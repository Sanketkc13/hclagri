# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14bKPxzSP2vC2EuC2EmxXFr5gi1ECsq4Z
"""

!pip install streamlit

!pip install --upgrade scikit-learn

import pandas as pd
import streamlit as st
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Load the dataset (Change path if needed)
dataset_path = '/content/drive/My Drive/agri/cleaned_dataset.csv'

# Function to load and preprocess the dataset
@st.cache_data
def load_data():
    try:
        df = pd.read_csv(dataset_path)
        print("Successfully loaded as CSV")
    except Exception as e:
        st.error(f"Failed to load as CSV: {e}")
        return None

    # Handle missing values
    df = df.dropna()  # Dropping rows with missing values

    # Convert categorical columns to numerical using label encoding
    le = LabelEncoder()
    categorical_cols = df.select_dtypes(include='object').columns
    for col in categorical_cols:
        df[col] = le.fit_transform(df[col])

    # Scale the data
    scaler = StandardScaler()
    df[df.columns] = scaler.fit_transform(df[df.columns])

    return df

# Function to smart fill values
def smart_fill_values(crop, month, state, city):
    smart_data = {}
    if month in [12, 1, 2]:
        smart_data['temperature_c'] = 18
    elif month in [3, 4, 5]:
        smart_data['temperature_c'] = 32
    elif month in [6, 7, 8, 9]:
        smart_data['temperature_c'] = 27
    else:
        smart_data['temperature_c'] = 24

    if month in [6, 7, 8, 9]:
        smart_data['rainfall_mm'] = 300
    else:
        smart_data['rainfall_mm'] = 50

    smart_data['supply_volume_tons'] = 500
    smart_data['demand_volume_tons'] = 520
    smart_data['transportation_cost_â‚¹/ton'] = 400
    smart_data['fertilizer_usage_kg/hectare'] = 110
    smart_data['pest_infestation_0-1'] = 0.3
    smart_data['market_competition_0-1'] = 0.5

    return smart_data

# Function to train the XGBoost model
def train_xgboost_model(df):
    X = df.drop(['price_â‚¹/ton'], axis=1)
    y = df['price_â‚¹/ton']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = XGBRegressor(objective='reg:squarederror')

    param_grid = {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.6, 0.8, 1.0]
    }

    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=3, verbose=1)
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_

    return best_model

# Function to smart fill values
def smart_fill_values(crop, month, state, city):
    smart_data = {}
    if month in [12, 1, 2]:
        smart_data['temperature_c'] = 18
    elif month in [3, 4, 5]:
        smart_data['temperature_c'] = 32
    elif month in [6, 7, 8, 9]:
        smart_data['temperature_c'] = 27
    else:
        smart_data['temperature_c'] = 24

    if month in [6, 7, 8, 9]:
        smart_data['rainfall_mm'] = 300
    else:
        smart_data['rainfall_mm'] = 50

    smart_data['supply_volume_tons'] = 500
    smart_data['demand_volume_tons'] = 520
    smart_data['transportation_cost_â‚¹/ton'] = 400
    smart_data['fertilizer_usage_kg/hectare'] = 110
    smart_data['pest_infestation_0-1'] = 0.3
    smart_data['market_competition_0-1'] = 0.5

    return smart_data

# Function to train the XGBoost model
def train_xgboost_model(df):
    X = df.drop(['price_â‚¹/ton'], axis=1)
    y = df['price_â‚¹/ton']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = XGBRegressor(objective='reg:squarederror')

    param_grid = {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.6, 0.8, 1.0]
    }

    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=3, verbose=1)
    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_

    # Optionally, you can evaluate the model on the test set
    y_pred = best_model.predict(X_test)
    st.write("Model Evaluation:")
    st.write(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}")
    st.write(f"Mean Squared Error: {mean_squared_error(y_test, y_pred):.2f}")
    st.write(f"RÂ² Score: {r2_score(y_test, y_pred):.2f}")

    return best_model

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import joblib  # For saving and loading the model
# %matplotlib inline

!pip install pandas xgboost scikit-learn

# Function to load and preprocess data
def load_and_preprocess_data(file):
    df = pd.read_csv(file)
    df['date'] = pd.to_datetime(df['date'])  # Convert date column to datetime
    df = df.dropna()  # Drop rows with missing values
    df = pd.get_dummies(df, columns=['state', 'city', 'crop_type', 'season'])  # One-hot encoding
    return df

# Function for Exploratory Data Analysis
def plot_correlation_matrix(df):
    plt.figure(figsize=(10, 8))
    numeric_df = df.select_dtypes(include=[np.number])  # Select only numeric columns
    sns.heatmap(numeric_df.corr(), annot=True, fmt=".2f", cmap='coolwarm', square=True, linewidths=0.5)
    plt.title("Correlation Heatmap")
    plt.show()

# Function to train the XGBoost model
def train_xgboost_model(df):
    # Define features and target variable
    X = df.drop(['price_â‚¹/ton'], axis=1)
    y = df['price_â‚¹/ton']

    # Train Test Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train XGBoost Model
    model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)
    model.fit(X_train, y_train)

    # Predict and Evaluate
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    return model, r2, mae, rmse

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle

# Load and preprocess the dataset
def preprocess(df):
    df['year'] = pd.to_datetime(df['date']).dt.year
    df['month'] = pd.to_datetime(df['date']).dt.month
    df = df.drop('date', axis=1)

    # Encode categorical features
    for col in df.select_dtypes(include='object').columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])

    return df

# Train the XGBoost model
def train_xgboost_model(df):
    # Prepare the features and target variable
    X = df.drop('price_â‚¹/ton', axis=1)
    y = df['price_â‚¹/ton']

    # Initialize and train the model
    model = xgb.XGBRegressor()
    model.fit(X, y)

    # Evaluate model performance
    y_pred = model.predict(X)
    mae = mean_absolute_error(y, y_pred)
    rmse = np.sqrt(mean_squared_error(y, y_pred))  # Fixed RMSE calculation
    r2 = r2_score(y, y_pred)

    return model, r2, mae, rmse

# Save the trained model
def save_model(model, filename):
    with open(filename, 'wb') as file:
        pickle.dump(model, file)

# Smart fill values based on crop, month, state, and city
def smart_fill_values(crop, month, state, city):
    """Smart filling based on crop, month, and location"""
    smart_data = {}

    # Approximate temperature based on month
    if month in [12, 1, 2]:
        smart_data['temperature_c'] = 18
    elif month in [3, 4, 5]:
        smart_data['temperature_c'] = 32
    elif month in [6, 7, 8, 9]:
        smart_data['temperature_c'] = 27
    else:
        smart_data['temperature_c'] = 24

    # Approximate rainfall based on season
    if month in [6, 7, 8, 9]:  # Monsoon
        smart_data['rainfall_mm'] = 300
    else:
        smart_data['rainfall_mm'] = 50

    # Default supply and demand values
    smart_data['supply_volume_tons'] = 500
    smart_data['demand_volume_tons'] = 520

    smart_data['transportation_cost_â‚¹/ton'] = 400
    smart_data['fertilizer_usage_kg/hectare'] = 110
    smart_data['pest_infestation_0-1'] = 0.3
    smart_data['market_competition_0-1'] = 0.5

    return smart_data

# Function to get user choices
def get_user_choice(prompt, options):
    print(prompt)
    for idx, option in enumerate(options, 1):
        print(f"{idx}. {option}")
    while True:
        try:
            choice = int(input("Enter choice number: "))
            if 1 <= choice <= len(options):
                return options[choice - 1]
            else:
                print("Invalid choice. Try again.")
        except ValueError:
            print("Invalid input. Enter a number.")

# Main function to run the application
def main():
    # Load and preprocess the dataset
    df = pd.read_csv('/content/drive/My Drive/agri/cleaned_dataset.csv')  # Updated dataset path
    df_processed = preprocess(df)

    # Train the model and evaluate it
    model, r2, mae, rmse = train_xgboost_model(df_processed)
    print(f"RÂ² Score: {r2:.2f}")
    print(f"Mean Absolute Error: {mae:.2f}")
    print(f"Root Mean Squared Error: {rmse:.2f}")

    # Save the trained model
    save_model(model, 'xgboost_agricultural_price_model.pkl')

    # --- User Inputs ---
    print("\nEnter inputs for Prediction:")

    # Choices from dataset
    states = sorted(df['state'].unique())
    cities = sorted(df['city'].unique())
    crops = sorted(df['crop_type'].unique())

    # State, City, Crop selection
    state = get_user_choice("\nSelect State:", states)
    city = get_user_choice("\nSelect City:", cities)
    crop_type = get_user_choice("\nSelect Crop Type:", crops)

    # Month input
    while True:
        try:
            month = int(input("\nEnter Month (1-12): "))
            if 1 <= month <= 12:
                break
            else:
                print("Month must be between 1 and 12.")
        except ValueError:
            print("Invalid input. Enter a number between 1 and 12.")

    year = 2025  # Default prediction year

    # Smart Auto-Fill
    smart_values = smart_fill_values(crop_type, month, state, city)

    # Prepare final input
    input_data = {
        'state': state,
        'city': city,
        'crop_type': crop_type,
        'season': 'Kharif',  # Default season
        'temperature_c': smart_values['temperature_c'],
        'rainfall_mm': smart_values['rainfall_mm'],
        'supply_volume_tons': smart_values['supply_volume_tons'],
        'demand_volume_tons': smart_values['demand_volume_tons'],
        'transportation_cost_â‚¹/ton': smart_values['transportation_cost_â‚¹/ton'],
        'fertilizer_usage_kg/hectare': smart_values['fertilizer_usage_kg/hectare'],
        'pest_infestation_0-1': smart_values['pest_infestation_0-1'],
        'market_competition_0-1': smart_values['market_competition_0-1'],
        'year': year,
        'month': month
    }

    input_df = pd.DataFrame([input_data])

    # Encode categorical inputs
    for col in input_df.select_dtypes(include='object').columns:
        le = LabelEncoder()
        le.fit(df[col])
        input_df[col] = le.transform(input_df[col])

    # Ensure column order matches
    input_df = input_df[df_processed.drop('price_â‚¹/ton', axis=1).columns]

    # Predict the price
    predicted_price = model.predict(input_df)[0]
    print(f"\nðŸŽ¯ Predicted Standard Price for {crop_type} in {city}, {state} during month {month}: â‚¹{predicted_price:.2f}")

if __name__ == "__main__":
    main()











